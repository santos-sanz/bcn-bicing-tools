{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading the Parquet File\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10078 entries, 0 to 10077\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   ttl           10078 non-null  int64         \n",
      " 1   last_updated  10078 non-null  int64         \n",
      " 2   data          10078 non-null  object        \n",
      " 3   timestamp     10078 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 315.1+ KB\n",
      "\n",
      "First few rows:\n",
      "   ttl  last_updated                                               data  \\\n",
      "0   -1    1694063435  {'stations': [{'is_charging_station': True, 'i...   \n",
      "1   -1    1694083661  {'stations': [{'is_charging_station': True, 'i...   \n",
      "2   -1    1694116657  {'stations': [{'is_charging_station': True, 'i...   \n",
      "3   -1    1694086176  {'stations': [{'is_charging_station': True, 'i...   \n",
      "4   -1    1694068296  {'stations': [{'is_charging_station': True, 'i...   \n",
      "\n",
      "            timestamp  \n",
      "0 2023-09-07 07:10:35  \n",
      "1 2023-09-07 12:47:41  \n",
      "2 2023-09-07 21:57:37  \n",
      "3 2023-09-07 13:29:36  \n",
      "4 2023-09-07 08:31:36  \n",
      "\n",
      "2. Reading Specific Columns\n",
      "\n",
      "Subset of data (first few rows):\n",
      "            timestamp                                               data\n",
      "0 2023-09-07 07:10:35  {'stations': [{'is_charging_station': True, 'i...\n",
      "1 2023-09-07 12:47:41  {'stations': [{'is_charging_station': True, 'i...\n",
      "2 2023-09-07 21:57:37  {'stations': [{'is_charging_station': True, 'i...\n",
      "3 2023-09-07 13:29:36  {'stations': [{'is_charging_station': True, 'i...\n",
      "4 2023-09-07 08:31:36  {'stations': [{'is_charging_station': True, 'i...\n",
      "\n",
      "3. Filtering Data\n",
      "\n",
      "Number of records after 2023-09-05 00:00:00: 4438\n",
      "\n",
      "4. Time Series Analysis\n",
      "\n",
      "Time series plot saved as 'analysis/hourly_records.png'\n",
      "\n",
      "5. Memory Efficiency\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/n2x_v3c9753_89hzt6068x340000gn/T/ipykernel_2879/3684005413.py:54: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hourly_counts = df['timestamp'].dt.floor('H').value_counts().sort_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 2.08 MB\n",
      "Selected columns size: 0.15 MB\n",
      "Filtered dataset size: 0.62 MB\n"
     ]
    }
   ],
   "source": [
    "# Reading and Analyzing Bicing Data from Parquet\n",
    "#\n",
    "# This script demonstrates how to read and analyze the Bicing data stored in Parquet format.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set plot style\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# 1. Reading the Parquet File\n",
    "print(\"1. Reading the Parquet File\\n\")\n",
    "\n",
    "# Read the Parquet file\n",
    "file_path = './compressed_data/all_data.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Reading Specific Columns\n",
    "print(\"\\n2. Reading Specific Columns\\n\")\n",
    "\n",
    "# Read only specific columns\n",
    "df_subset = pd.read_parquet(\n",
    "    file_path,\n",
    "    columns=['timestamp', 'data']\n",
    ")\n",
    "print(\"Subset of data (first few rows):\")\n",
    "print(df_subset.head())\n",
    "\n",
    "# 3. Filtering Data\n",
    "print(\"\\n3. Filtering Data\\n\")\n",
    "\n",
    "# Read data for a specific date range\n",
    "start_date = datetime(2023, 9, 5)\n",
    "df_filtered = pd.read_parquet(\n",
    "    file_path,\n",
    "    filters=[(\"timestamp\", \">\", start_date)]\n",
    ")\n",
    "\n",
    "print(f\"Number of records after {start_date}: {len(df_filtered)}\")\n",
    "\n",
    "# 4. Time Series Analysis\n",
    "print(\"\\n4. Time Series Analysis\\n\")\n",
    "\n",
    "# Group by hour and count records\n",
    "hourly_counts = df['timestamp'].dt.floor('H').value_counts().sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "hourly_counts.plot(kind='line')\n",
    "plt.title('Number of Records per Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Records')\n",
    "plt.grid(True)\n",
    "plt.savefig('./compressed_data/hourly_records.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Time series plot saved as 'analysis/hourly_records.png'\")\n",
    "\n",
    "# 5. Memory Efficiency\n",
    "print(\"\\n5. Memory Efficiency\\n\")\n",
    "\n",
    "def get_size_df(df):\n",
    "    return df.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "\n",
    "# Full dataset\n",
    "df_full = pd.read_parquet(file_path)\n",
    "print(f\"Full dataset size: {get_size_df(df_full):.2f} MB\")\n",
    "\n",
    "# Only specific columns\n",
    "df_cols = pd.read_parquet(file_path, columns=['timestamp', 'ttl'])\n",
    "print(f\"Selected columns size: {get_size_df(df_cols):.2f} MB\")\n",
    "\n",
    "# Filtered dataset\n",
    "df_filtered = pd.read_parquet(\n",
    "    file_path,\n",
    "    filters=[(\"timestamp\", \">\", datetime(2023, 9, 6))]\n",
    ")\n",
    "print(f\"Filtered dataset size: {get_size_df(df_filtered):.2f} MB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the number of records is the same and the space saved\n",
    "import os\n",
    "\n",
    "folder = '../snapshots'\n",
    "target_format = 'json'\n",
    "\n",
    "def list_folders(folder):\n",
    "    \"\"\"\n",
    "    List all subdirectories in the specified folder.\n",
    "    :param folder: Path to the main folder.\n",
    "    :return: List of folder names.\n",
    "    \"\"\"\n",
    "    return [name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))]\n",
    "\n",
    "def list_files(folder):\n",
    "    \"\"\"\n",
    "    List all files in the specified directory.\n",
    "    :param folder: Path to the directory.\n",
    "    :return: List of file names.\n",
    "    \"\"\"\n",
    "    return [name for name in os.listdir(folder) if os.path.isfile(os.path.join(folder, name))]\n",
    "\n",
    "def list_all_files(main_folder, dates):\n",
    "    \"\"\"\n",
    "    List all files within subdirectories specified by dates under the main folder.\n",
    "    :param main_folder: Path to the main folder.\n",
    "    :param dates: List of subdirectory names to search within.\n",
    "    :return: List of file paths.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for date in dates:\n",
    "        folder = os.path.join(main_folder, date)\n",
    "        for file in list_files(folder):\n",
    "            files.append(os.path.join(folder, file))\n",
    "    return files\n",
    "\n",
    "def get_total_size_mb(folder, dates):\n",
    "    \"\"\"\n",
    "    Calculate total size of all files in the specified folders in MB.\n",
    "    :param folder: Path to the main folder.\n",
    "    :param dates: List of subdirectory names to search within.\n",
    "    :return: Total size in MB.\n",
    "    \"\"\"\n",
    "    total_bytes = 0\n",
    "    for file_path in list_all_files(folder, dates):\n",
    "        total_bytes += os.path.getsize(file_path)\n",
    "    return total_bytes / (1024 * 1024)  # Convert bytes to MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in parquet dataset: 10078\n",
      "Number of records in JSON files: 10078\n",
      "Records difference: 0\n",
      "---------------------------------------------------------\n",
      "Pandas memmory dataset size: 2.08 MB\n",
      "Parquet file size: 31.11 MB\n",
      "Size of JSON files: 1668.64 MB\n",
      "Compression ratio (JSON/Parquet): 53.64x\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_parquet(file_path)\n",
    "\n",
    "print(f\"Number of records in parquet dataset: {len(df_full)}\")\n",
    "print(f\"Number of records in JSON files: {len(list_all_files(folder,list_folders(folder)))}\")\n",
    "print(f\"Records difference: {len(df_full)-len(list_all_files(folder,list_folders(folder)))}\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(f\"Pandas memmory dataset size: {get_size_df(df_full):.2f} MB\")\n",
    "\n",
    "file_path = './compressed_data/all_data.parquet'\n",
    "if os.path.isfile(file_path):\n",
    "    compressed_size = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"Parquet file size: {compressed_size:.2f} MB\")\n",
    "else:\n",
    "    print(\"Parquet file not found\")\n",
    "\n",
    "json_size = get_total_size_mb(folder, list_folders(folder))\n",
    "print(f\"Size of JSON files: {json_size:.2f} MB\")\n",
    "\n",
    "compression_ratio = json_size / compressed_size\n",
    "print(f\"Compression ratio (JSON/Parquet): {compression_ratio:.2f}x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_charging_station</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>is_renting</th>\n",
       "      <th>is_returning</th>\n",
       "      <th>last_reported</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_bikes_available_types</th>\n",
       "      <th>num_bikes_disabled</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_docks_disabled</th>\n",
       "      <th>station_id</th>\n",
       "      <th>status</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1694063319</td>\n",
       "      <td>22</td>\n",
       "      <td>{'ebike': 3, 'mechanical': 19}</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1694083623</td>\n",
       "      <td>29</td>\n",
       "      <td>{'ebike': 9, 'mechanical': 20}</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1694116639</td>\n",
       "      <td>20</td>\n",
       "      <td>{'ebike': 1, 'mechanical': 19}</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1694086034</td>\n",
       "      <td>28</td>\n",
       "      <td>{'ebike': 8, 'mechanical': 20}</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1694068096</td>\n",
       "      <td>28</td>\n",
       "      <td>{'ebike': 8, 'mechanical': 20}</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_charging_station  is_installed  is_renting  is_returning  last_reported  \\\n",
       "0                 True             1           1             1     1694063319   \n",
       "1                 True             1           1             1     1694083623   \n",
       "2                 True             1           1             1     1694116639   \n",
       "3                 True             1           1             1     1694086034   \n",
       "4                 True             1           1             1     1694068096   \n",
       "\n",
       "   num_bikes_available       num_bikes_available_types  num_bikes_disabled  \\\n",
       "0                   22  {'ebike': 3, 'mechanical': 19}                   0   \n",
       "1                   29  {'ebike': 9, 'mechanical': 20}                   0   \n",
       "2                   20  {'ebike': 1, 'mechanical': 19}                   0   \n",
       "3                   28  {'ebike': 8, 'mechanical': 20}                   0   \n",
       "4                   28  {'ebike': 8, 'mechanical': 20}                   0   \n",
       "\n",
       "   num_docks_available  num_docks_disabled station_id      status traffic  \n",
       "0                   21                   0         10  IN_SERVICE    None  \n",
       "1                   14                   0         10  IN_SERVICE    None  \n",
       "2                   23                   0         10  IN_SERVICE    None  \n",
       "3                   15                   0         10  IN_SERVICE    None  \n",
       "4                   15                   0         10  IN_SERVICE    None  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a specific station data\n",
    "station_id = 10\n",
    "df_full = pd.read_parquet(file_path)\n",
    "stations_df = pd.DataFrame([row['stations'][station_id-1] for row in df_full['data']])\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated yearly dataset size: 84.97 GB\n",
      "Estimated yearly compressed dataset size: 1.58 GB\n"
     ]
    }
   ],
   "source": [
    "current_dataset_size = ((1668.64/7)*365/1024)\n",
    "compresed_dataset_size = current_dataset_size/53.64\n",
    "\n",
    "print(f\"Estimated yearly dataset size: {current_dataset_size:.2f} GB\")\n",
    "print(f\"Estimated yearly compressed dataset size: {compresed_dataset_size:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
